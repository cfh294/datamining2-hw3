{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.4 64-bit",
   "display_name": "Python 3.7.4 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "e534e48711db4d1e1c48977d0d14ff85b1f16d41bcc4fdfd88268a329b3c9d66"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Homework 3 &mdash; Digit Classifier\n",
    "\n",
    "### Connor Hornibrook\n",
    "\n",
    "### Data Mining II &mdash; Dr. Breitzman"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Classifier and source data\n",
    "\n",
    "For this script, I decided to use the ```sklearn.svm.SVC``` classifier to do predictions. All source data was pulled from [Kaggle](https://www.kaggle.com/c/digit-recognizer/data). The trained model included in this repository has an accuracy of roughly 97%."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all needed libraries, configure basic logging\n",
    "import pathlib\n",
    "import pandas\n",
    "import pickle\n",
    "import logging\n",
    "import csv\n",
    "import numpy\n",
    "from statistics import mean\n",
    "from sklearn import linear_model, svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that loads training data from csv, and returns a dataframe\n",
    "def get_data(directory=pathlib.Path(\".\", \"data\"), train_pattern=\"train.csv\"):\n",
    "    train_path = directory / train_pattern\n",
    "    return pandas.read_csv(str(train_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that retrieves an SVC object. If there is a model saved locally under models/,\n",
    "# then this will simply unpack the bytes using pickle and return the model object. \n",
    "# If not, then it will create a new model from scratch, using the training data provided from Kaggle.     \n",
    "def get_model(train_data, directory=pathlib.Path(\".\", \"models\")):\n",
    "    path = directory / \"model.bin\"\n",
    "    if path.exists():\n",
    "        logging.info(\"Loading model from memory.\")\n",
    "        with open(str(path), \"rb\") as f:\n",
    "            model = pickle.load(f)\n",
    "    else:\n",
    "        logging.info(\"No model found in memory, creating one now.\")\n",
    "        model = svm.SVC(gamma=\"scale\")\n",
    "        scaler = MinMaxScaler(feature_range=(0, 255))\n",
    "        scores = []\n",
    "        y = train_data.label.to_numpy()\n",
    "        x = scaler.fit_transform(\n",
    "            train_data.drop(columns=\"label\")\n",
    "        )\n",
    "        logging.info(\"Training model...\")\n",
    "        kf = KFold(n_splits=10)\n",
    "        for train_i, test_i in kf.split(x):\n",
    "            x_train, y_train = x[train_i], y[train_i]\n",
    "            x_test, y_test = x[test_i], y[test_i]\n",
    "            model.fit(x_train, y_train)\n",
    "            scores.append(model.score(x_test, y_test))\n",
    "        logging.info(\"Done.\")\n",
    "        logging.info(f\"Accuracy: {mean(scores)}\")\n",
    "        with open(str(path), \"wb\") as f:\n",
    "            pickle.dump(model, f)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that makes predictions against the test.csv file from Kaggle, \n",
    "# and outputs it to output/output.csv\n",
    "def make_predictions(model):\n",
    "    in_path = str(pathlib.Path(\".\", \"data\", \"test.csv\"))\n",
    "    out_path = str(pathlib.Path(\".\", \"output\", \"output.csv\"))\n",
    "    logging.info(\"Making predictions...\")\n",
    "    with open(in_path, \"r\") as in_data_file, open(out_path, \"w\") as out_file:\n",
    "        i = 1\n",
    "        writer = csv.writer(out_file)\n",
    "        writer.writerow([\"ImageId\", \"Label\"])\n",
    "        reader = csv.reader(in_data_file)\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            writer.writerow(\n",
    "                [\n",
    "                    i,\n",
    "                    model.predict(numpy.array([row]))[0]\n",
    "                ]\n",
    "            )\n",
    "            i += 1\n",
    "    logging.info(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put it all together, grab data, grab model, make predictions\n",
    "def main():\n",
    "    make_predictions(\n",
    "        get_model(\n",
    "            get_data()\n",
    "        )\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:root:Loading model from memory.\n",
      "INFO:root:Making predictions...\n",
      "INFO:root:Done.\n"
     ]
    }
   ],
   "source": [
    "# run the program\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ]
}